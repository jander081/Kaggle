{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market - > Features Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../scripts'\n",
    "import sys\n",
    "sys.path.append(path)\n",
    "from market_imports import *\n",
    "from market_code import *\n",
    "\n",
    "data_path = '/Users/jacob/Desktop/docs/kaggle/two_sigma/_g_data/data'\n",
    "df_market = pd.read_csv(data_path + '/marketdata_sample.csv') \n",
    "df_news = pd.read_csv(data_path + '/news_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIST OF ASSETS PULLED FROM KERNEL \n",
    "# with open('output/asset_kernel.txt', 'w') as file:\n",
    "#     file.write(str(assets))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRYING TO PREVENT DATE TYPE CONVERSION\n",
    "# THIS SHOULD BE UPDATED FROM PANDA DATAREADER\n",
    "csv = pd.read_csv(data_path + '/sigma_data.csv', index_col='Date', parse_dates=True, \n",
    "                 infer_datetime_format=True)\n",
    "\n",
    "print(csv.shape)\n",
    "\n",
    "check = csv.columns[:4].tolist()\n",
    "csv.drop_duplicates(check, inplace=True)\n",
    "\n",
    "print(csv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPUTE RESIDUAL FOR RESPONSE\n",
    "import statsmodels.tsa.api as tsa\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose \n",
    "\n",
    "x = csv[['returns_open_raw10_next']]\n",
    "# Freq will depend on asset number - this needs to be researched\n",
    "result = seasonal_decompose(x, model='additive', freq=50)\n",
    "\n",
    "csv['returns_res10_next'] = result.resid\n",
    "# Lose the first and last day\n",
    "csv = csv[-csv['returns_res10_next'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.Close.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.Close.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELC is insanely high. The next highest price is around 300\n",
    "csv[csv.Close ==csv.Close.max()]\n",
    "csv[csv.Close > 1000]\n",
    "csv = csv[csv.asset != 'ELC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = csv.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF YOU WANT TO UPDATE\n",
    "\n",
    "# with open('/Users/jacob/Desktop/docs/kaggle/two_sigma/_g_data/output/asset.txt',\n",
    "#          'r') as file:\n",
    "#     assets = file.read()\n",
    "# file.close()  \n",
    "##################################\n",
    "\n",
    "# assets = ['CHL.N', 'RAD.N', 'HBC', 'PDNT.O', 'IGLD.O', '0857.F', 'GOOGa.DE', 'DIS.N', '1285.HK', 'DIS.F', 'MTTX.O', 'NDAQ.O', 'ALBK.F', 'AAPL.OQ', 'GS.N', 'WF.N', 'HTX.N', 'UPM1V.HE', 'GE.N', 'LPL.N', 'RYAAY.OQ', 'MHR.A', 'KB.N', '1301.HK', 'YHOO.O', 'SRIB.O', 'RYAAY.O', '2332.DE', 'YHOO.OQ', 'TRV.DE', '0941.HK', 'SIRI.O', 'UPM.N', 'SIEB.O', 'DWMT.O', 'NGG.N', '3777.HK', 'NML.A', 'NWS.N', 'SAN.MC', 'PGEB.O', 'MER.N', 'DSP.A', 'MON.DE', 'NOKy.DE', 'ADBE.DE', 'MTTT.O', 'SI.N', '3838.HK', 'NG.L', 'NOKS.DE', 'QCOM.DE', 'DIS.DE', 'CS.AS', 'TSM.N', 'C', 'MTNK.O', 'AAPL.F', '0005.HK', 'QCOM.O', 'IGLD.TA', 'ADBE.OQ', 'SIEB.OQ', 'STZb.N', 'AIB.N', 'BEN.N', 'IGLD.OQ', 'SNE.N', 'TWX.N', 'DCX.N', 'THC.N', 'MSFT.DE', 'NWSa.N', 'ISAT.JK', '0857.HK', '053000.KS', 'NWS.AX', 'WMT.DE', 'AUO.N', 'SIEGnq.L', 'KEP.N', 'BHP.F', 'ELC.A', '2332.HK', 'AAPL.DE', 'NOK1V.HE', 'WSH.N', '2330.TW', 'MX.N', 'NOKS.F', 'XMSR.O', 'FMSAUBD.MX', 'BHP.N', 'SIRI.OQ', 'PLJC.O', 'MSPX.O', 'NOK.N', 'YHOO.DE', 'CHLy.DE', 'DCXGn.F', 'SIEGn.DE', 'STZ.N', '0941.F', 'STD.BA', 'ALBK.I', '015760.KS', 'STD.N', 'VIAb.N', 'CSNA3.SA', '7267.T', 'MSFT.O', 'C.N', 'AAPL.O', '0941.DE', 'MNNY.O', 'RBS.L', 'TIE.N', 'HMC.N', '6758.T', 'HSBA.L', 'NDAQ.OQ', 'ALBK.L', 'MTSM.O', 'EST.A', 'IIT.N', 'WMT.N', '0857.DE', 'VIA.N', 'RBV.N', 'MLN.P', 'BHP.AX', 'CTCH.O', 'RBS.DE', 'CGA.N', 'MON.F', 'CS.L', 'GOOG.OQ', 'MON.N', 'SASY.PA', 'MEO1V.HE', 'SIEGn.F', '2409.TW', 'DCXGn.DE', 'STA.N', 'SASY.F', 'ADBE.O', 'SNY.N', 'RBS', 'RYA.I', '034220.KS', 'RYA.L', 'MSFT.OQ', 'RYA.F', 'MSFT.F', 'HBC.N', 'VNV.N', 'HBC.PA', 'FMX.N', 'QCOM.OQ', '060000.KS', 'TRV.F', 'GOOG.O', 'PTR.N', 'SID.N']\n",
    "# sub_asst = assets[:200]\n",
    "\n",
    "# sub = [i.split('.')[0] for i in sub_asst]     \n",
    "\n",
    "# data = marketDataGen(sub)\n",
    "\n",
    "# data.to_csv(data_path + '/sigma_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data[data.asset.isin(['AAPL'])]\n",
    "test = test[['asset', 'Close']]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = csv.copy()\n",
    "\n",
    "data['ema_26'] = data.groupby('asset')['Close'].transform(lambda x: x.ewm(span=26, \n",
    "                                                                          adjust=False).mean())\n",
    "\n",
    "data['ema_12'] = data.groupby('asset')['Close'].transform(lambda x: x.ewm(span=12, \n",
    "                                                                          adjust=False).mean())\n",
    "\n",
    "\n",
    "data['ema_9'] = data.groupby('asset')['Close'].transform(lambda x: x.ewm(span=9, \n",
    "                                                                          adjust=False).mean())\n",
    "\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT TO FUNC\n",
    "# scored pretty low on importance. sma_20 is included for bollinger. Thats enough for now. Could consider a crossover\n",
    "# indicator\n",
    "data = csv.copy()\n",
    "\n",
    "spans = [5, 20, 50]\n",
    "for span in spans:\n",
    "    print(span)\n",
    "    data['sma_' + str(span)] = data.groupby('asset')['Close'].transform(lambda x: x.rolling(window=span).mean())\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MACD \n",
    "\n",
    "If correlation becomes an issue, could consider crossover indicators easy enough  \n",
    "\n",
    "\n",
    "\n",
    "Moving average convergence divergence (MACD) is a trend-following momentum indicator that shows the relationship between two moving averages of prices. The MACD is calculated by subtracting the 26-day exponential moving average (EMA) from the 12-day EMA. A nine-day EMA of the MACD, called the \"signal line\", is then plotted on top of the MACD, functioning as a trigger for buy and sell signals.\n",
    "\n",
    "MACD can be interpreted using 3 different methods:\n",
    "\n",
    "__Crossover__: When the MACD falls bellow the signal line (9-day EMA) this is a bearish signal. When the MACD rise above the signal line, this is a bulish signal.\n",
    "\n",
    "__Divergence__: When the price diverges from MACD, it signal the end of the current trend\n",
    "\n",
    "__Dramatic Rise__: When MACD rises dramatically, that is, the shorter moving average pulls away from the longer-term moving average, this is a signal that the stock is overbought\n",
    "\n",
    "Source: https://www.investopedia.com/terms/m/macd.asp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MACD - MANUAL\n",
    "data = csv.copy() \n",
    "\n",
    "ema_26 = data.groupby('asset')['Close'].transform(lambda x: x.ewm(span=26).mean())\n",
    "ema_12 = data.groupby('asset')['Close'].transform(lambda x: x.ewm(span=12).mean())\n",
    "data['macd'] = ema_12 - ema_26\n",
    "\n",
    "data['signal'] = data.groupby('asset')['macd'].transform(lambda x: x.ewm(span=9).mean())\n",
    "\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MACD - BETTER FORM\n",
    "data = csv.copy() \n",
    "\n",
    "def macd(dframe):\n",
    "    \n",
    "    asset_close = dframe.groupby('asset')['Close']\n",
    "    ema_26 = asset_close.transform(lambda x: x.ewm(span=26).mean())\n",
    "    ema_12 = asset_close.transform(lambda x: x.ewm(span=12).mean())\n",
    "    \n",
    "    return ema_12 - ema_26\n",
    "\n",
    "data['macd'] = macd(data)\n",
    "\n",
    "data['signal'] = (\n",
    "                data.groupby('asset')['macd'].\n",
    "                transform(lambda x: x.ewm(span=9).\n",
    "                mean() )\n",
    "                )\n",
    "\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = csv.copy() \n",
    "\n",
    "def macd(dframe):\n",
    "    \n",
    "    \"\"\"\n",
    "    If macd is negative/positive, the shorter term mv avg is below/above the longer \n",
    "    term and momentum is downward/upward - ish.\n",
    "    \n",
    "    If the signal is simply the ema of macd. If macd is less/greater than the signal,\n",
    "    whether pos or neg, the momentum is bear/bullish\n",
    "    \n",
    "    Ex\n",
    "    -----\n",
    "    both signal and macd are negative. However, macd is noticably less\n",
    "    negative than the signal. Interpretation: the asset has been in a short term down\n",
    "    trend (short term down trend could be part of a long term down/up trend). However, \n",
    "    the momentum is bullish\n",
    "    \n",
    "    Metrics for indicators\n",
    "    ------\n",
    "    Crossover: macd is below/above signal\n",
    "    \n",
    "    Divergence: the price diverges by a certain threshold from macd. End of \n",
    "    current trend\n",
    "    \n",
    "    Dramatic Rise: macd is significantly above signal - overbought\n",
    "       \n",
    "    \"\"\"\n",
    "    \n",
    "    asset_close = dframe.groupby('asset')['Close']\n",
    "    ema_26 = asset_close.transform(lambda x: x.ewm(span=26).mean())\n",
    "    ema_12 = asset_close.transform(lambda x: x.ewm(span=12).mean())\n",
    "    # switch adjusted back to default\n",
    "    \n",
    "    return ema_12 - ema_26\n",
    "\n",
    "\n",
    "\n",
    "data['macd'] = macd(data)\n",
    "\n",
    "data['signal'] = (\n",
    "                data.groupby('asset')['macd'].\n",
    "                transform(lambda x: x.ewm(span=9).\n",
    "                mean() )\n",
    "                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT TO ARRAYS\n",
    "macd = data['macd'].values\n",
    "sig = data['signal'].values\n",
    "close = data['Close'].values\n",
    "diff = macd - sig # dramatic rise\n",
    "div = abs(close - macd) # diverge\n",
    "\n",
    "# VECTORIZED (FASTER) -> SET AS BOOLS FOR PIPELINES\n",
    "data['macd_cross'] = np.where(macd > sig, 1, 0).astype('bool')\n",
    "data['macd_sharp_rise'] = np.where(diff > 0.09, 1, 0).astype('bool')\n",
    "data['macd_div'] = np.where(div > 75, 1, 0).astype('bool')\n",
    "\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRETTY LOUSY SUMMARY STATS FROM NUMPY. PUT IN PANDAS FOR STATS.\n",
    "# definitely some serious outliers. Need to think about outlier reduction\n",
    "\n",
    "import scipy\n",
    "scipy.stats.describe(div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE QUARTILES FOR NOW. IF IN THE UPPER 80%, THEN CLASSIFY AS DIVERGING. SAME THING FOR DRAMATIC RISE. MEAN AND STD\n",
    "# can't be trusted until the outliers are dealt with\n",
    "pd.DataFrame(div).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bollinger Band  \n",
    "\n",
    "https://www.investopedia.com/articles/technical/04/030304.asp  \n",
    "\n",
    "\n",
    "\n",
    "Equities alternate between periods of low volatility and high volatility–much like the calm before the storm and the inevitable activity afterward.\n",
    "\n",
    "__squeeze__ $= \\frac{UB - LB}{SMA}$  \n",
    "\n",
    "Squeeze candidate is identified as a 6 month low. So, add the feature and then add a 6 month trailing minimum indicator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUAL\n",
    "data = csv.copy() \n",
    "\n",
    "sd_20 = df.groupby('asset')['Close'].transform(lambda x: x.rolling(window=20).std())\n",
    "\n",
    "sma_20 = df.groupby('asset')['Close'].transform(lambda x: x.rolling(window=20).mean())\n",
    "\n",
    "df['BB_upper'] = sma_20 + (sd_20*2)\n",
    "\n",
    "df['BB_lower'] = sma_20 - (sd_20*2)\n",
    "\n",
    "                                    \n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = csv.copy() \n",
    "\n",
    "def BB(dframe):\n",
    "    \n",
    "    \n",
    "    asset_close = dframe.groupby('asset')['Close']\n",
    "    \n",
    "    sd_20 = (\n",
    "            asset_close.\n",
    "            transform( lambda x: x.rolling(window=20).\n",
    "            std() )\n",
    "            )\n",
    "\n",
    "    sma_20 = (\n",
    "            asset_close.\n",
    "            transform(lambda x: x.rolling(window=20).\n",
    "            mean())\n",
    "            )\n",
    "\n",
    "    \n",
    "    return ( sma_20 + (sd_20*2), sma_20 - (sd_20*2) )\n",
    "\n",
    "\n",
    "data['BB_upper'], data['BB_lower'] = BB(data)\n",
    "\n",
    "                                    \n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = csv.copy() \n",
    "\n",
    "def BB_distance(dframe):\n",
    "    \n",
    "    '''price moves toward upper indicate bullish. This\n",
    "    returns the distance from stock price to upper or lower \n",
    "    BB. If the distance turns negative, the price is above/below. \n",
    "    See indicator lambdas.\n",
    "    \n",
    "     Squeeze is calculate per asset. However, comparing it to the 6 month min is a bit\n",
    "    more involved. For now, leave it external. It can be integrated into the func/class\n",
    "    later if it is useful. Notice the shift on the rolling min(). The present squeeze value\n",
    "    should not be included in the window we are comparing it with.\n",
    "    '''\n",
    "    \n",
    "    asset_close = dframe.groupby('asset')['Close']\n",
    "    \n",
    "    sd_20 = (\n",
    "            asset_close.\n",
    "            transform(lambda x: x.rolling(window=20).\n",
    "            std()).\n",
    "            values        \n",
    "            )\n",
    "    \n",
    "    sma_20 = (\n",
    "            asset_close.\n",
    "            transform(lambda x: x.rolling(window=20).\n",
    "            mean()).\n",
    "            values\n",
    "            )\n",
    "    \n",
    "    # convert everything to arrays\n",
    "    \n",
    "    close = dframe['Close'].values   \n",
    "    U = sma_20 + (sd_20*2)    \n",
    "    L = sma_20 - (sd_20*2) \n",
    "    squeeze = (U - L)/ sma_20\n",
    "\n",
    "    \n",
    "#     return (U - close, close - L, squeeze)\n",
    "    return (U, L, squeeze)\n",
    "\n",
    "U, L,  squeeze = BB_distance(data)\n",
    "    \n",
    "    \n",
    "# data['BB_upper_dis'], data['BB_lower_dis'],  data['squeeze']= BB_distance(data)\n",
    "    \n",
    "    \n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = csv.copy()\n",
    "# A SHIFT IS INCLUDED TO EXCLUDE THE CURRENT VALUE TO BE COMPARED\n",
    "data['squeeze'] = squeeze\n",
    "sq_min = (\n",
    "        data.groupby('asset')['squeeze'].\n",
    "        transform(lambda x: x.rolling(window=126).\n",
    "        min().\n",
    "        shift())\n",
    "        )\n",
    "\n",
    "data['low_vol'] = np.where(squeeze <= sq_min, 1, 0).astype('bool')\n",
    "# data['min'] = sq_min\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOOKS LIKE ANY DISTANCE BELOW 0.3 IS LESS THAN 20%\n",
    "\n",
    "C = data['Close'].values\n",
    "data['Bollinger_bearish'] = np.where(C-L <= 0.3, 1, 0).astype('bool')\n",
    "data['Bollinger_bullish'] = np.where(U-C <= 0.3, 1, 0).astype('bool')\n",
    "\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RSI  \n",
    "\n",
    "Original code. Walthrough (single asset), then custom function with groupby/transform/lambda. Time on 4M + set decent. Could look to vectorize later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_strength_index(close, n):\n",
    "    \"\"\"Calculate Relative Strength Index(RSI) for given data.\n",
    "    \n",
    "    :param df: pandas.Series\n",
    "    :param n: \n",
    "    :return: pandas.DataFrame\n",
    "    \"\"\"\n",
    "    buf = pd.DataFrame()\n",
    "    buf['close'] = close\n",
    "    buf['diff'] = buf.close.diff()\n",
    "    mask = buf['diff'] < 0\n",
    "    buf['high'] = abs(buf['diff'].mask(mask))\n",
    "    buf['low'] = abs(buf['diff'].mask(~mask))\n",
    "    buf['high'] = buf['high'].fillna(0)\n",
    "    buf['low'] = buf['low'].fillna(0)\n",
    "    posrs = buf['high'].ewm(span=n, min_periods=n).mean()\n",
    "    negrs = buf['low'].ewm(span=n, min_periods=n).mean()\n",
    "    buf['rsi'] =  posrs / (posrs + negrs)\n",
    "    return buf.rsi\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUAL METHOD -> ONE ASSET AT A TIME (OR ELSE IT WILL MERGE EVERYTHING)\n",
    "test['diff'] = test.Close.diff()\n",
    "mask = test['diff'] < 0\n",
    "test['high'] = abs(test['diff'].mask(mask)).fillna(0)\n",
    "test['low'] = abs(test['diff'].mask(~mask)).fillna(0)\n",
    "pos_rsi = test['high'].ewm(span=14, min_periods=14).mean()\n",
    "neg_rsi = test['low'].ewm(span=14, min_periods=14).mean()\n",
    "test['rsi'] =  pos_rsi / (pos_rsi + neg_rsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION METHOD - single asset\n",
    "# simply replacing cols with unassigned panda series\n",
    "# cannot imagine this is very fast\n",
    "diff = test.Close.diff()\n",
    "mask = diff < 0\n",
    "high = abs(diff.mask(mask)).fillna(0)\n",
    "low = abs(diff.mask(~mask)).fillna(0)\n",
    "pos_rsi = high.ewm(span=14).mean()\n",
    "neg_rsi = low.ewm(span=14).mean()\n",
    "test['rsi'] =  pos_rsi / (pos_rsi + neg_rsi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET UP FOR A LAMBDA COLUMN TRANSFORM\n",
    "# as used, the incoming vec is the asset.Close\n",
    "\n",
    "def rsi(x):\n",
    "    \n",
    "    diff = x.diff()\n",
    "    mask = diff < 0\n",
    "    high = abs(diff.mask(mask)).fillna(0)\n",
    "    low = abs(diff.mask(~mask)).fillna(0)\n",
    "    pos_rsi = high.ewm(span=14).mean()\n",
    "    neg_rsi = low.ewm(span=14).mean()\n",
    "    return  pos_rsi / (pos_rsi + neg_rsi)\n",
    "\n",
    "\n",
    "# TESTED WITH 2 ASSETS. SEEMS TO WORK. CLOSE IS PULLED FROM THE FUNCTION\n",
    "# the x is the asset.Close\n",
    "test['rsi'] = test.groupby('asset')['Close'].transform(lambda x: rsi(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (base)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
