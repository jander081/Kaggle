{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4c4708dcbcef9b0ad3d0a966324806498269fbef"
   },
   "source": [
    "## LGB Submission and metric breakdown\n",
    "\n",
    "MARKET DATA ONLY - This is only for submission\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notes:__ However, you will not get a score back unless you commit the kernel and submit to Kaggle. Still need to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "\n",
    "\n",
    "# copy our file into the working directory (make sure it has .py suffix)\n",
    "copyfile(src = \"../input/supporting-files-sigma/sigma_libs.py\", dst = \"../working/sigma_libs.py\")\n",
    "copyfile(src = \"../input/supporting-files-sigma/sigma_1.py\", dst = \"../working/sigma_1.py\")\n",
    "copyfile(src = \"../input/supporting-files-sigma/preproc2.py\", dst = \"../working/preproc2.py\")\n",
    "# import all our functions\n",
    "from sigma_libs import *\n",
    "from sigma_1 import *\n",
    "from preproc2 import *\n",
    "tqdm.pandas() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "249b4b7740a3ae182adec9b465ab8316e9a634d6"
   },
   "outputs": [],
   "source": [
    "df_market, df_news = env.get_training_data()\n",
    "# MARKET DATA ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "29012deff4d1185fe0872a5f1fa4ba2f697b3ea5"
   },
   "outputs": [],
   "source": [
    "# MARKET ONLY\n",
    "del df_news\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e525a0a2b1498b67641cc653045673a45c5eb05a"
   },
   "outputs": [],
   "source": [
    "# SOME BASIC ENGINEERING\n",
    "\n",
    "def train_feats(dframe):\n",
    "    # could do list comp\n",
    "    train_feat = []\n",
    "    for col in dframe.columns:\n",
    "        if col not in ['time', 'assetCode', 'universe', 'returnsOpenNextMktres10']:\n",
    "            train_feat.append(col)\n",
    "    return train_feat\n",
    "\n",
    "def preproc(dframe):\n",
    "    \n",
    "   \n",
    "    dframe['avg'] = (dframe.close + dframe.open)/2\n",
    "    dframe['pricevolume'] = dframe.volume * df_market.close\n",
    "    dframe.drop(['assetName'], axis=1, inplace=True)\n",
    "    \n",
    "    # REDUCED - arbitrary    \n",
    "    start = datetime(2012, 1, 1, 0, 0, 0).date()\n",
    "    df_= dframe.loc[dframe['time'].dt.date >= start].reset_index(drop=True)\n",
    "    # This form of date is better for setting the ranges later\n",
    "    df_['time'] = df_.time.dt.strftime(\"%Y%m%d\").astype(int)\n",
    "\n",
    "    return df_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "054c63657b4b46b5468791df28966a5cd9bdea7f"
   },
   "outputs": [],
   "source": [
    "# MINI PIPELINE\n",
    "df_m = df_market.copy() \n",
    "df = preproc(df_m)\n",
    "train_feat = train_feats(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e525a0a2b1498b67641cc653045673a45c5eb05a"
   },
   "outputs": [],
   "source": [
    "# SET RANGES\n",
    "# There should be a better way to do this. But this is quick and based off\n",
    "# percentiles. I would initially go be dates to set the ranges. Doesn't need \n",
    "# to be an int. Could include this in a Time_ class.\n",
    "dates = df['time'].unique()\n",
    "\n",
    "train_range = range(len(dates))[:int(0.85*len(dates))]\n",
    "val_range = range(len(dates))[int(0.85*len(dates)):]\n",
    "\n",
    "# Convert targets to binary\n",
    "target = ['returnsOpenNextMktres10']\n",
    "df[target[0]] = (df[target[0]] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__So lightgbm is awesome, fast, and efficient. Time to drop xgb and make this your go-to model__\n",
    "\n",
    "\n",
    "Preload the data into the model as numpy arrays. It has a zillon parameters and other options. The validation set is embedded into the model. Allows the model to train against the validation set and then select the best iteration. I'd have to research this more. Typically, validations are only used like this for NN. It's not using CV, just the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "# THIS INSTATIATES IT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e525a0a2b1498b67641cc653045673a45c5eb05a"
   },
   "outputs": [],
   "source": [
    "# KINDA LOOKS CRAPPY. THIS JUST SETS THE TRAINING/VAL SETS WITH PREDICTORS\n",
    "# train data - numpys\n",
    "X_train = df[train_feat].fillna(0).loc[df['time'].isin(dates[train_range])].values\n",
    "Y_train = df[target].fillna(0).loc[df['time'].isin(dates[train_range])].values\n",
    "\n",
    "# GETS INTERESTING -> INPUTS DATA INTO INSTANCE\n",
    "lgb_train = lgb.Dataset(X_train, Y_train[:,0])\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eec34ae95870bbe3624ea8b57d456d30647eeb6f"
   },
   "outputs": [],
   "source": [
    "# validation data - numpys\n",
    "X_v = df[train_feat].fillna(0).loc[df['time'].isin(dates[val_range])].values\n",
    "Y_v = df[target].fillna(0).loc[df['time'].isin(dates[val_range])].values\n",
    "\n",
    "lgb_val = lgb.Dataset(X_v, Y_v[:,0]),\n",
    "print(X_v.shape, Y_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "18e5a219538157a4fc1c42bd9e49bbd180bf4d31"
   },
   "outputs": [],
   "source": [
    "\n",
    "param = {\"objective\" : \"binary\",\n",
    "          \"metric\" : \"binary_logloss\",\n",
    "          \"verbosity\" : -1 }\n",
    "\n",
    "# TONS OF HYPERPARAMENTERS. THIS FIT FUNC USES THE VAL SET TO TRAIN AND \n",
    "# SELECT THE BEST ITERATION\n",
    "\n",
    "model = lgb.train(param, lgb_train, valid_sets=lgb_val, \n",
    "                  early_stopping_rounds=10) \n",
    "                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily test data\n",
    "\n",
    "Need to explore this more. But I think we get the picture. Initially, the set that I looked at was around 2k entries. This is somwhat consistent with the number of assets for a given day. My question: how many days are we talking about here? We know the training sets cut out at the start of 2018 (confirm). I know this is two phased. We need a better understanding of the testing processes. This is synthetic data, so phase 2 uses real data that is current?  \n",
    "\n",
    "market _train_ data $\\approx 40.7$ million (feb2007 to dec2016)  \n",
    "\n",
    "market _test_ data $\\approx 1800$ (jan2017). __I believe this is per day. so in actuality, if the test set covers 2017, we're looking at 657K. Double that if we include 2018__  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "41d6a63fd93d3e0f2ea841995eecd8011512fff2"
   },
   "outputs": [],
   "source": [
    "# SO RUN THIS FIRST, IT WILL RETURN THE 3 OBJECTS (DFRAMES) FOR EACH DAY\n",
    "days = env.get_prediction_days()\n",
    "# THE AUTHOR USED THIS TO GRAB ONE DAY FOR ANALYSIS\n",
    "# (market_obs_df, news_obs_df, predictions_template_df) = next(days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "_uuid": "aadf63238ea54064d08b3b13f4ea56928b24ecf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission file has been saved. Once you `Commit` your Kernel and it finishes running, you can submit the file to the competition from the Kernel Viewer `Output` tab.\n"
     ]
    }
   ],
   "source": [
    "# NEED TO LOOP THROUGH EACH DAY AND RENDER PREDICTIONS\n",
    "\n",
    "for market, news, pred_df in days:\n",
    "    # preprocess\n",
    "    X = preproc(market)\n",
    "    # predictors\n",
    "    X_test = X[train_feat].fillna(0).values\n",
    "    # pred vec -> *2 -1 (need to check this math)\n",
    "    preds = model.predict(X_test, num_iteration=model.best_iteration) * 2 - 1\n",
    "    # create dframe for my preds\n",
    "    df_pred = pd.DataFrame({'ast':X['assetCode'],'conf':preds})\n",
    "    # if my predicted asset is in the provided kaggle dframe, then\n",
    "    # set the kaggle feat [con val] == to my prediction\n",
    "    pred_df['confidenceValue'][pred_df['assetCode'].isin(df_pred.ast)] = df_pred['conf'].values\n",
    "    # upload predictions \n",
    "    env.predict(pred_df)\n",
    "\n",
    "env.write_submission_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sure about how many days. But if you like, you can break the _daily_ dframes down. Nothing special, but need to inspect further. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "41d6a63fd93d3e0f2ea841995eecd8011512fff2"
   },
   "outputs": [],
   "source": [
    "X = preproc(market_obs_df)\n",
    "\n",
    "X_test = X[train_feat].fillna(0).values\n",
    "\n",
    "preds = model.predict(X_test, num_iteration=model.best_iteration) * 2 - 1\n",
    "\n",
    "preds_toDF = pd.DataFrame({'ast':X['assetCode'],'conf':preds})\n",
    "\n",
    "preds_toDF.shape\n",
    "\n",
    "predictions_template_df['confidenceValue'][predictions_template_df['assetCode'].isin(preds_toDF.ast)] = preds_toDF['conf'].values\n",
    "\n",
    "predictions_template_df.shape\n",
    "\n",
    "env.predict(predictions_template_df)\n",
    "\n",
    "env.write_submission_file()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "335e31c4c12bf46f06eefa0ed223ac9c9e2ea9a9"
   },
   "outputs": [],
   "source": [
    "(market_obs_df, news_obs_df, predictions_template_df) = next(days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "53ca6744130bd66a01894aba705563d5b16f7cdd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d43e6bde6fc3387c0bb126c8bf67e9b3b3656be7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sigma)",
   "language": "python",
   "name": "sigma"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
