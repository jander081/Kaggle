{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graveyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAKEN FROM ASSETEXPAND CLASS. REPLACED WITH VECTORIZE FOR PROCESSING SPEED\n",
    "def to_vec(self):\n",
    "\n",
    "        # returns clean series with lists of assets. \n",
    "\n",
    "        vec = self.data[self.col].apply(lambda x: re.sub(r'[{}\\']', '', x))\n",
    "        # remove extra spaces\n",
    "        vec = vec.apply(lambda x: x.replace(\" \", \"\"))\n",
    "        # a bit of a band aid. str.split was throwing errors when added above\n",
    "        # print(vec.head(2))\n",
    "        return pd.Series([i.split(',') for i in vec])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSET FEATURE EXPANSION, MY ORIGINAL VERSION - (SO SLOW)\n",
    "import re\n",
    "asset_col = news_train['assetCodes'].apply(lambda x: re.sub(r'[{}\\']', '', x).split(','))\n",
    "\n",
    "df_idx = pd.DataFrame()\n",
    "for i in range(0,asset_col.size):\n",
    "    index = asset_col.index[i]\n",
    "    for j in range(0, len(asset_col[i])):\n",
    "        df_idx = pd.concat([df_idx, pd.Series([asset_col[i][j]], \n",
    "                                              index=[index])], axis=0)\n",
    "\n",
    "df_news = pd.concat([df_idx, news_train], axis=1,\n",
    "                 join='outer',join_axes=[df_idx.index]).reset_index(drop=True) \n",
    "                                                                    \n",
    "df_news.drop(['assetCodes'], axis=1, inplace=True)\n",
    "\n",
    "df_news.rename(columns={0:'assetCode'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM EDA FORK. PROTOTYPE FUNC\n",
    "\n",
    "# disagree with drops\n",
    "def preprocess_news(news_train):\n",
    "    drop_list = [\n",
    "        'audiences', 'subjects', 'assetName',\n",
    "        'headline', 'firstCreated', 'sourceTimestamp',\n",
    "    ]\n",
    "    news_train.drop(drop_list, axis=1, inplace=True)\n",
    "    \n",
    "    # Factorize categorical columns\n",
    "    for col in ['headlineTag', 'provider', 'sourceId']:\n",
    "        news_train[col], uniques = pd.factorize(news_train[col])\n",
    "        del uniques\n",
    "    \n",
    "    # Remove {} and '' from assetCodes column\n",
    "    news_train['assetCodes'] = news_train['assetCodes'].apply(lambda x: x[1:-1].replace(\"'\", \"\"))\n",
    "    return news_train\n",
    "\n",
    "news_train = preprocess_news(news_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MORE ASSET EXPANSION CODE\n",
    "# THIS WASN'T USED, BUT IT COULD HAVE BEEN\n",
    "sub = df_news.subjects.apply(lambda x: re.sub(r'[{}\\']', '', x)).replace(\" \", \"\")\n",
    "lst = []\n",
    "for i in sub:\n",
    "    val = i.split()\n",
    "    lst.extend(val)\n",
    "    \n",
    "col_names = list(set([i.replace(',', '') for i in lst]))\n",
    "col_names = list(set([i.strip(' \\n,') for i in lst]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tried to dynamically import\n",
    "\n",
    "def import_class(modulename, classname):\n",
    "    ''' Returns imported class. '''\n",
    "    try:\n",
    "        return getattr(__import__(modulename, globals(), locals(), [classname], -1), classname)\n",
    "    except AttributeError:\n",
    "        print('Error in importing class. \"%s\" has no class \"%s\"' % (modulename, classname))\n",
    "        return None\n",
    "    except ImportError as e:\n",
    "        print('Error in importing class: %s' % (e))\n",
    "        return None\n",
    "\n",
    "mymodule = import_class(\"sigma_libs\", \"*\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "from importlib.import_module(\"sigma_libs\") import *\n",
    "\n",
    "mymodule = importlib.import_module('matplotlib.text')\n",
    "imported_module = __import__(file) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# still trying vectorize\n",
    "def vec_func(x):\n",
    "    if x <= 0.25:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "vf = np.vectorize(vec_func, cache=False)\n",
    "data['Bollinger_bearish'] = vf(data['BB_lower_dis']).astype('bool')\n",
    "data['Bollinger_bullish'] = vf(data['BB_upper_dis']).astype('bool')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra - possible use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BACKTRADER\n",
    "'''backtrader looks interesting. May be worth comparing to \n",
    "Quandle or zipline'''\n",
    "class SmaCross(bt.SignalStrategy):\n",
    "        params = (('pfast', 10), ('pslow', 30),)\n",
    "        def __init__(self):\n",
    "            sma1, sma2 = bt.ind.SMA(period=self.p.pfast), bt.ind.SMA(period=self.p.pslow)\n",
    "            self.signal_add(bt.SIGNAL_LONG, bt.ind.CrossOver(sma1, sma2))\n",
    "\n",
    "cerebro = bt.Cerebro()\n",
    "\n",
    "data = bt.feeds.YahooFinanceData(dataname='MSFT', fromdate=datetime(2016, 1, 1),\n",
    "                                 todate=datetime(2019, 1, 31))\n",
    "\n",
    "# help(data.array)\n",
    "\n",
    "cerebro.adddata(data)\n",
    "\n",
    "cerebro.addstrategy(SmaCross)\n",
    "cerebro.run()\n",
    "cerebro.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOME PLOTTING CODE TO GO THROUGH  \n",
    "set([asset for asset in df_market.assetCode if re.match(r'AMZ', asset)])\n",
    "\n",
    "amzn_jan = df_market[(df_market.time.dt.year == 2007) & \n",
    "                      (df_market.assetCode == 'AMZN.O')]\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "# plt.plot(range(len(aapl_jan.time)), aapl_jan.close, label='Close price')\n",
    "# plt.plot(range(len(aapl_jan.time)), aapl_jan.open, label='Open price')\n",
    "plt.title(\"Opening and closing price\")\n",
    "plt.plot(amzn_jan.time, amzn_jan.open, label='Open price')\n",
    "plt.plot(amzn_jan.time, amzn_jan.close, label='Close price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title(\"Opening and closing return mtres 1\")\n",
    "plt.bar(range(len(amzn_jan.time)), amzn_jan.returnsOpenPrevMktres1, label='Return Open price')\n",
    "plt.bar(range(len(amzn_jan.time)), amzn_jan.returnsClosePrevMktres1, label='Return Close price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# LOG RETURNS\n",
    "amzn_daily_return = np.log(amzn_jan.close/ amzn_jan.close.shift(1))\n",
    "\n",
    "# NON-LOG\n",
    "amzn_daily_return_non = amzn_jan.close/ amzn_jan.close.shift(1) - 1\n",
    "pd.concat([amzn_daily_return, amzn_daily_return_non], axis=1).head()\n",
    "# CLOSE BUT DEFINITELY SLIGHTLY DIFFERENT\n",
    "amzn_daily_return.hist(bins=50)\n",
    "\n",
    "# SOME NANS - BUT A VERY LOW PERCENT. PROBABLY FROM THE SHIFT, WHICH IS \n",
    "# WHY THE NANS ARE FRONT LOADED - SEEMINGLY\n",
    "\n",
    "df_market = df_market.assign(\n",
    "    daily_percent_price=df_market.groupby('assetCode',\n",
    "                                            as_index=False).apply(lambda x: np.log(x.close/ x.close.shift(1)))\n",
    "    .reset_index(0, drop=True)\n",
    ")\n",
    "\n",
    "# df_market.daily_percent_price.isnull().sum() / df_market.daily_percent_price.size\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "ax1 = plt.subplot(221)\n",
    "df_market.query(\"time.dt.year == 2016 and assetCode == 'AAPL.O'\")['daily_percent_price'].hist(bins=50)\n",
    "ax2 = plt.subplot(222)\n",
    "df_market.query(\"time.dt.year == 2016 and assetCode == 'AMZN.O'\")['daily_percent_price'].hist(bins=50)\n",
    "ax3 = plt.subplot(223)\n",
    "df_market.query(\"time.dt.year == 2016 and assetCode == 'A.N'\")['daily_percent_price'].hist(bins=50)\n",
    "ax4 = plt.subplot(224)\n",
    "df_market.query(\"time.dt.year == 2016 and assetCode == 'CMC.N'\")['daily_percent_price'].hist(bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTERESTING GROUPBY METHOD\n",
    "# NEED TO RUN THE DATE FUNC FIRST\n",
    "df_g = (\n",
    "    df.\n",
    "    reset_index().\n",
    "    sort_values(['asset', 'date']).\n",
    "    set_index(['asset','date'])\n",
    ")\n",
    "\n",
    "test = df.groupby('asset')\n",
    "\n",
    "for name,group in test:\n",
    "    print(name)\n",
    "    print(group)\n",
    "\n",
    "0.000000 - -0.075508\n",
    "\n",
    "(df.\n",
    "    groupby('asset').\n",
    "    apply(lambda x: x.returns_close_raryw - x.returns_open_raw10).\n",
    "    reset_index(0, drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cool convolution\n",
    "N=20\n",
    "np.convolve(qcom, np.ones((N,))/N, mode='valid')[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATTEMPT TO VECTORIZE - Multi-indexing was really slow\n",
    "\n",
    "mult = csv.copy()\n",
    "mult.set_index(['assetCode', 'time'], inplace=True)\n",
    "mult.sort_index(inplace=True)\n",
    "\n",
    "sma_v = np.array([])\n",
    "\n",
    "sma = np.zeros(df.shape[0])\n",
    "for asset in assets:\n",
    "    print(asset)\n",
    "    X = mult['close'].loc[asset].values\n",
    "    x = np.arange(X.shape[0])\n",
    "    def sma(i, n=20):\n",
    "        return np.nansum(X[i-n+1:i+1]) / n\n",
    "    vf = np.vectorize(sma)\n",
    "    # print(vf(x)[-5:])\n",
    "    arr = vf(x)\n",
    "    sma_v = np.concatenate((sma_v, arr))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant",
   "language": "python",
   "name": "quant"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
